# regressao-linear-teste-e-prever-resultados

![Badge em Desenvolvimento](http://img.shields.io/static/v1?label=STATUS&message=EM%20DESENVOLVIMENTO&color=GREEN&style=for-the-badge)

![Badge code size](https://img.shields.io/github/languages/code-size/fab-souza/regressao-linear-teste-e-prever-resultados)
<!---
![GitHub Org's stars](https://img.shields.io/github/stars/fab-souza/regressao-linear-teste-e-prever-resultados?style=social)
--> 


| :placard: Vitrine.Dev |    |
| -------------  | --- |
| :sparkles: Nome        | **Regress√£o Linear: testando rela√ß√µes e prevendo resultados**
| :label: Tecnologias | python
| :rocket: URL         | 
| :fire: Desafio     | Conte√∫do do 5¬∫ [curso](https://www.alura.com.br/curso-online-data-science-modelo-regressao-linear) da forma√ß√£o [Data Science](https://www.alura.com.br/formacao-data-science)

![](https://github.com/fab-souza/regressao-linear-teste-e-prever-resultados/assets/67301805/ff56c32e-f5c1-4882-a49f-188f758c489c#vitrinedev)


# Sobre o curso üìö

Continuando a p√¥r em pr√°tica o que aprendi nos cursos da forma√ß√£o Data Science da [Alura](https://www.alura.com.br/), j√° passei pela an√°lise e explora√ß√£o dos dados, agora chegou a vez de falar sobre os modelos de previs√£o. Neste curso, tamb√©m ministrado pelo instrutor [Rodrigo Dias](https://www.linkedin.com/in/rodrigo-fernando-dias-118181120/), aprendi:

- sobre a import√¢ncia das visualiza√ß√µes para compreender a distribui√ß√£o dos dados;

- a diferen√ßa entre vari√°veis dependentes e explicativas;

- a import√¢ncia de separar os dados em conjuntos de treino e teste;

- a criar modelos que relacionam as vari√°veis dependentes e explicativas, permitindo previs√µes e an√°lises estat√≠sticas;

- compreender os erros em fun√ß√£o dos res√≠duos e m√©tricas, ou seja, identificar poss√≠veis discrep√¢ncias entre as previs√µes e os valores reais;

- finalizando com a compara√ß√£o e salvamento dos melhores modelos. 

Desta vez, utilizamos dados dispon√≠veis no [Kaggle](https://www.kaggle.com/datasets/dongeorge/beer-consumption-sao-paulo) sobre o consumo de cerveja em uma regi√£o na cidade de S√£o Paulo.

![image](https://github.com/fab-souza/regressao-linear-teste-e-prever-resultados/assets/67301805/6139fb64-2328-4665-a099-8c8d3e119696)

Ao longo do curso, desenvolvemos um modelo de Machine Learning capaz de fazer a previs√£o do consumo m√©dio de cerveja, utilizando a Regress√£o Linear. 

![image](https://github.com/fab-souza/regressao-linear-teste-e-prever-resultados/assets/67301805/7bf21f17-e69c-48f0-abc6-1c4ee2357b04)


# Minha pr√°tica üë©üèª‚Äçüíª

Para esta pr√°tica, pensei em utilizar um dataset sobre consumo de energia, tamb√©m disponibilizado no [Kaggle](https://www.kaggle.com/datasets/fedesoriano/electric-power-consumption). 
Ele cont√©m informa√ß√µes sobre os registros de temperatura, umidade, velocidade do vento e o consumo de energia de 3 regi√µes da cidade Tetouan, situada no norte do Marrocos. 
Os registros come√ßaram em 1¬∫ de janeiro de 2017 e v√£o at√© o dia 30 de dezembro do mesmo ano, com um intervalo de 10 minutos entre eles.

![image](https://github.com/fab-souza/regressao-linear-teste-e-prever-resultados/assets/67301805/82524c48-be9a-4d6c-9efe-4e3366e1bb81)

Na descri√ß√£o do dataset, n√£o √© informado quais s√£o as unidades de medida das vari√°veis, mas uma delas possui um exemplo em ¬∞C. Ent√£o, vou supor que as vari√°veis seguem as mesmas unidades de medidas usadas aqui no Brasil.

* Temperatura = ¬∞C
* Umidade = %

E aqui veio uma vari√°vel um pouco complicada de determinar. Para a velocidade do vento, eu encontrei p√°ginas citando o uso de m/s, km/h e n√≥s (kt). 
Ao fazer um *.describe()* do DataFrame, vi que o valor m√≠nimo dela √© **0,05** e seu m√°ximo √© de **6,48**. 

![image](https://github.com/fab-souza/regressao-linear-teste-e-prever-resultados/assets/67301805/7c50d4b2-2dd3-4705-83ff-9d935ac86eab)

A p√°gina [Clima de Ensinar](https://www.climadeensinar.com/post/2016/09/08/como-%C3%A9-medida-a-velocidade-do-vento) possui uma tabela que ilustra como classificar o vento de acordo com sua velocidade nas tr√™s unidades de medida, m/s, km/h e n√≥s.

![image](https://github.com/fab-souza/regressao-linear-teste-e-prever-resultados/assets/67301805/e8e89a11-920a-4b59-b47e-02e96739d864)

Se a unidade de medida do dataset fosse em km/h, ou em n√≥s, a cidade n√£o teria ventos diferentes de *brisa leve*, pois este tipo de vento vai at√© 12km/h, ou 6 n√≥s. Se estiver em m/s, os ventos podem ser classificados chegar at√© *brisa moderada*, que v√£o at√© 7,4m/s.

Fiz uma pesquisa no Google sobre a cidade, onde tive acesso ao clima da regi√£o, com registro da temperatura, umidade e velocidade do vento (em km/h). 

![image](https://github.com/fab-souza/regressao-linear-teste-e-prever-resultados/assets/67301805/30c29072-1ae0-4515-a5b8-ac4b2540021d)

Para transformar km/h para m/s, divido por 3,6.  

![image](https://github.com/fab-souza/regressao-linear-teste-e-prever-resultados/assets/67301805/21cb5c39-fac4-477e-9d5c-b927d46e021b)

Fonte: [Prepare Enem](https://www.preparaenem.com/fisica/como-passar-m-s-para-km-h.htm)

Fazendo 21 km/h para m/s, tenho 5,83 m/s, valor este que est√° dentro da faixa registrada no dataset. Portanto:

* Velocidade do vento = m/s
* Consumo de energia = kWh

---
Com as unidades de medida estabelecidas, iniciei a manipula√ß√£o do dataset.
Diferente do dataset usado no curso, neste caso eu n√£o tenho informa√ß√µes como temperatura m√≠nima, m√©dia, m√°xima e se o dia est√° em um fim de semana ou n√£o. Ao fazer um gr√°fico de correla√ß√£o, vi que, com exce√ß√£o dos **consumos** e **fluxos**, as demais vari√°veis n√£o possuem correla√ß√£o superior a 0,5 e decidi adicionar as colunas semelhantes do dataset usado no curso para ver se elas melhoravam.

![image](https://github.com/fab-souza/regressao-linear-teste-e-prever-resultados/assets/67301805/48200778-7c96-45b8-8769-3754ab293c50)

Para criar as vari√°veis referentes a m√≠nima, m√©dia e m√°xima de algumas colunas, eu poderia fazer igual ao dataset do curso e descobrir o quanto os valores variaram ao longo do dia, mas acho que perderia muitos dados ao fazer essa compacta√ß√£o. Dessa forma, achei melhor agrupar as informa√ß√µes por hora.

O Pandas tem um m√©todo que faz a reamostragem de s√©ries temporais, o **resample**. Tive que definir uma regra, que √© o intervalo da reamostragem, informar a coluna em forma de *datetime* e, fora do m√©todo, o que eu queria de retorno, se √© o m√≠nimo, o m√°ximo, etc.

No caso dos **consumos**, eu precisava da soma do que foi registrado no intervalo de 1 hora e defini o retorno da reamostragem como **resultado_soma**. Nas demais colunas, este tipo de reamostragem n√£o seria √∫til e as exclu√≠.

Para descobrir as m√©dias, tamb√©m utilizei o **resample** e nomeie seu retorno como **resultado_media**. Neste caso, a reamostragem dos consumos n√£o √© relevante e retirei elas do DataFrame. Eu tamb√©m fiz este procedimento para descobrir os m√≠nimos e m√°ximos destas colunas, para s√≥ ent√£o, unir todas elas em um dataset maior. 

Na reamostragem de m√≠nimo e m√°ximo, tamb√©m exclu√≠ as 3 colunas do consumo e adicionei um sufixo nas colunas, para diferenci√°-las umas das outras. Para evitar a repeti√ß√£o, criei uma fun√ß√£o que remove as colunas e adiciona os sufixos.

Na hora de unir os DataFrame, por algum motivo ü§î, algumas colunas tiveram o sufixo retirado. Fiz a altera√ß√£o dos nomes e terminei de unir os 4 DataFrame.

![image](https://github.com/fab-souza/regressao-linear-teste-e-prever-resultados/assets/67301805/4baeee49-2203-4d15-b4d1-6cf5879d229c)

Para fazer classifica√ß√£o dos dias, se √© no fim de semana ou n√£o, primeiramente, tive que restaurar o √≠ndice, como o m√©todo **.reset_index**. Depois, utilizei o m√©todo **weekday**, do m√≥dulo *datetime*, que funciona da seguinte forma, para cada dia, ele retorna um inteiro, por exemplo, segunda-feira √© ‚Äò0‚Äô e domingo √© ‚Äò6‚Äô. Criei uma fun√ß√£o que preenche uma nova coluna no dataset com ‚Äò0‚Äô e ‚Äò1‚Äô. Para os retornos do **weekday** maiores ou iguais a 5 (s√°bado e domingo) a coluna √© preenchida com ‚Äò1‚Äô, caso contr√°rio, recebe ‚Äò0‚Äô.

## Nova correla√ß√£o:

Ap√≥s todas as manipula√ß√µes, fiz uma nova correla√ß√£o e o resultado n√£o foi muito diferente da primeira. Em todas as vari√°veis reajustadas, n√£o houve grande mudan√ßa de valores. A **Temperatura** continua sendo a vari√°vel com maior correla√ß√£o, a **Umidade** continua apresentando valores negativos e **Velocidade do vento**, **Fluxos gerais** e **Fluxos difusos** continuaram com seus valores baixos, pr√≥ximos √† 0. J√° para a nova vari√°vel, **Fim de semana**, sua correla√ß√£o com os consumos tamb√©m fica pr√≥ximo √† 0 nas tr√™s subesta√ß√µes, valor positivo apenas para a Zona 3 e negativo nas outras duas.

![image](https://github.com/fab-souza/regressao-linear-teste-e-prever-resultados/assets/67301805/a57c51e0-dc09-48d9-96a4-422ec312f460)

## Criando o modelo:

Para dar in√≠cio a cria√ß√£o do modelo, importei a fun√ß√£o **train_test_split**, da biblioteca *Scikit_learn*, que separa os dados em duas partes, *Treino* e *Teste*, um para treinar o modelo e o outro para test√°-lo.

Defini o **Consumo_zona3** como **y**, **Temperatura**, **Umidade** e **Velocidade_vento** como **X**, passei ambas para a fun√ß√£o **train_test_split**, tamb√©m defini a porcentagem de dados usados para o teste e um valor para o **random_state**.

Importei m√©todos destinados √† regress√£o, **linear_model**, **LinearRegression** e **metrics**. Iniciei um modelo de regress√£o linear vazio e o treinei com os dados de treinamento, **X_train** e **y_train**, com a fun√ß√£o **.fit()**

Para avaliar o desempenho do modelo, calculei o coeficiente de determina√ß√£o com o **.score()**. Ele √© um m√©todo que retorna a precis√£o m√©dia do modelo ao comparar os valores previstos para *X_train* com os valores verdadeiros de *y_train*. Ou seja, representa a qualidade do ajuste do modelo aos dados e n√£o obtive um bom resultado: **0,238**

Ele trabalha com valores entre 0 e 1, e quanto mais pr√≥ximo de 1, melhor. Ou seja, n√£o √© um bom modelo. Eu j√° sabia que duas, das tr√™s, vari√°veis independentes n√£o estavam fortemente correlacionadas ao **Consumo**, ent√£o, n√£o deveria esperar um bom modelo como resultado.

Em uma forma de tentar melhorar o modelo, troquei a **Umidade** por **Fluxos_gerais**, criei um novo modelo e o coeficiente melhorou um pouco. De 0,238 passou para 0,271. 

Com esta pequena melhora, resolvi tentar usar o novo modelo para prever um consumo de energia. Criei uma vari√°vel, *y_previsto*, para receber as previs√µes de **X_test** e comparei seus resultados com os valores originais, **y_test**, atrav√©s da fun√ß√£o **metrics.r2_score()**. Seu valor tamb√©m varia entre 0 e 1, ele mostra o quanto o modelo se ajustou aos dados e seu retorno foi de **0,282**. Ou seja, o modelo consegue explicar 28,2% das varia√ß√µes dos dados.

Para finalizar, eu quis ver o qu√£o pr√≥ximo o modelo chegou de um dado, atrav√©s de uma previs√£o pontual. Atribu√≠ a vari√°vel *entrada* o primeiro registro em **X_test**, coletando sua temperatura, velocidade do vento e fluxos gerais. Passei para o m√©todo **.predict()** a nova vari√°vel e ele retornou o valor de **20408.79**.

Ou seja, para um per√≠odo com temperatura de 27,44 ¬∞C, ventos de 4,9 m/s e fluxos gerais de 818, a previs√£o de consumo √© de 20.408,79 kWh.

No entanto, fiz um *.loc* do √≠ndice do primeiro registro de **X_test** e vi que o consumo de energia, nas condi√ß√µes registradas, foi de 27.986,61 kWh na Zona 3.

![image](https://github.com/fab-souza/regressao-linear-teste-e-prever-resultados/assets/67301805/6f4bfdde-4215-4baa-80ff-1bb9b355f20e)


# Conclus√£o üèÅ

Eu j√° tinha conhecimento de que o **Consumo** n√£o tinha forte correla√ß√£o com as demais vari√°veis, exceto **Temperatura**, e mesmo assim continuei trabalhando com este dataset. Como resultado, o modelo n√£o foi capaz de explicar grande parte da varia√ß√£o nos dados. 

Eu ainda poderia tentar utilizar outros modelos de regress√£o, para ver se os resultados melhoravam, mas n√£o era o foco do curso, eu n√£o quis avan√ßar e bordar o conte√∫do de um curso que ainda n√£o fiz um projeto sobre.

Com o projeto finalizado, fui ver o material da aula e percebi que cometi um grande erro:
-antes de come√ßar qualquer manipula√ß√£o com os dados, eu deveria ter verificado se os **Consumos** possuem uma distribui√ß√£o normal. Se ela n√£o fosse atendida, eu n√£o poderia executar testes, pois n√£o teria resultados confi√°veis.

![image](https://github.com/fab-souza/regressao-linear-teste-e-prever-resultados/assets/67301805/9b3a264a-62ea-4c5c-9910-80e999a1fbec)

Sem contar que: ‚Äò*Garbage in, garbage out*‚Äô

N√£o adianta tentar fazer milagre com um dataset que n√£o apresenta bons dados, fica de li√ß√£o para os pr√≥ximos projetos.

## Ferramentas utilizadas üß∞

